---
name: v0.1.1 Mock Interview Module
overview: Implement the Mock Interview (Gauntlet) MVP with turn-based Q&A flow, AI orchestration via hidden signals, resume context loading, surrender mechanic, roast feedback system, and session governance with time/question limits.
todos:
  - id: mock-foundation
    content: "Create mock package structure: state.go (InterviewState enum, messages), constants.go (limits, prompts, grades), keymap.go (Surrender binding)"
    status: pending
  - id: protocol-engine
    content: "Implement protocol.go: ParseSignals() function using regexp to extract <NEXT> and <ROAST> signals, return cleaned content and flags"
    status: pending
  - id: context-loader
    content: "Implement context.go: LoadContext() reads .txt/.md files, wrapped in tea.Cmd for non-blocking I/O, error handling for missing files"
    status: pending
  - id: core-model
    content: "Implement model.go: Main interview model with state machine (Waiting→AIThinking→UserInput→Roasting), integrate AI streaming, turn/question tracking"
    status: pending
  - id: roast-system
    content: "Implement roast.go: CalculateGrade(), GetPersonaLabel(), RenderRoast(), RenderRemediationButtons() with lipgloss styling"
    status: pending
  - id: surrender-mechanic
    content: "Add surrender flow: Tab key handler in UserInput state, inject shadow prompt, render inline micro-roast (bold red), increment counter"
    status: pending
  - id: session-limits
    content: "Implement session governance: time tracking (tea.Tick), question counting, expiry detection, pulsing [FINAL QUESTION] alert in status bar"
    status: pending
  - id: cli-command
    content: "Create internal/cli/mock.go: Cobra command with --resume flag, initialize AI client, launch TUI, handle resume path from profile or flag"
    status: pending
  - id: ui-input
    content: "Add user answer input: bubbles/textinput component, multi-line support, Enter submits answer, integrate with state machine"
    status: pending
  - id: ui-polish
    content: "Polish UI: status bar rendering, pulsing alerts, help text updates (internal/ui/help.go), key binding overrides for interview context"
    status: pending
  - id: testing
    content: "Test edge cases: empty resume, AI errors, timeouts, protocol signal parsing, state transitions, graceful exit"
    status: pending
---

# v0.1.1 Implementation Plan - Mock Interview Module (The Gauntlet MVP)

## Architecture Overview

Create a new `mock` command and TUI model that orchestrates a turn-based interview flow:

- User answers questions one at a time
- AI decides when to follow-up or move to next question via hidden signals
- System tracks session metadata and enforces limits
- Visual feedback for surrenders and final roast/grade

## File Structure

```
internal/
  mock/                          # New package for mock interview
    model.go                     # Main TUI model (interviews state machine)
    state.go                     # Interview state types and transitions
    protocol.go                  # Protocol engine for parsing <NEXT>/<ROAST> signals
    context.go                   # Resume/CV context loader (.txt, .md)
    roast.go                     # Roast rendering (grade, persona, remediation)
    constants.go                 # Interview constants (limits, prompts, grades)
    keymap.go                    # Mock-specific key bindings
  cli/
    mock.go                      # Cobra command: `prepf mock [--resume PATH]`
  ui/
    base.go                      # Extend State enum (StateInterviewWaiting, etc.)
    keymap.go                    # Add Surrender key binding
    help.go                      # Update help text for mock-specific keys
```

## Implementation Details

### 1. Sequential Interview Engine

**`internal/mock/model.go`** - Main interview model:

- Embed `*ui.BaseModel` for base functionality
- State machine: `InterviewWaiting` → `InterviewAIThinking` → `InterviewUserInput` → `InterviewRoast`
- Turn counter, question count, surrender count tracking
- Session start time for 15-min limit enforcement
- AI response buffer (streaming) and user answer buffer
- Integrate with existing `ai.Client` for streaming

**`internal/mock/protocol.go`** - Signal parser:

- `ParseSignals(text string) (content string, hasNext bool, hasRoast bool)`
- Regexp: `<NEXT>`, `<ROAST>` (case-insensitive, strip from display)
- Returns cleaned content and boolean flags for state transitions

**`internal/mock/context.go`** - Resume loader:

- `LoadContext(path string) (string, error)` - reads `.txt` or `.md` files
- Wrapped in `tea.Cmd` for non-blocking file I/O
- Inject into initial AI prompt: "Here is the user's resume: {content}. Conduct a technical interview..."

**`internal/mock/state.go`** - State definitions:

- `InterviewState` enum: `Waiting`, `AIThinking`, `UserInput`, `Roasting`
- Message types: `ContextLoaded`, `QuestionReceived`, `AnswerSubmitted`, `SurrenderTriggered`, `RoastTriggered`, `SessionExpired`

### 2. The "Roast" Mechanics

**`internal/mock/roast.go`** - Roast rendering:

- `CalculateGrade(surrenders int, questions int) string` - A-F based on surrenders (more surrenders = lower grade)
- `GetPersonaLabel(grade string) string` - e.g., "[A] - ARCHITECT MATERIAL", "[F] - TERMINATED"
- `RenderRoast(grade, persona, feedback string) string` - High-contrast lipgloss box
- `RenderRemediationButtons(topics []string) string` - 3 interactive buttons (placeholders, non-functional in v0.1.1)

**Surrender Flow:**

- `Tab` key in `UserInput` state triggers `SurrenderTriggered` message
- Inject shadow prompt: "User surrenders. Give a snappy 1-2 sentence correction and move on."
- Render inline micro-roast (bold red via lipgloss) immediately
- Increment surrender counter, continue to next question

**Verdict Screen:**

- Triggered by `<ROAST>` signal or session expiry
- Display grade box (large, centered)
- Show persona label
- Render 3 remediation buttons (UI only, no action handlers yet)

### 3. Session Governance

**Time/Question Limits:**

- Constants in `internal/mock/constants.go`: `MaxQuestions = 10`, `MaxDurationMinutes = 15`
- Check on each turn: `if questionCount >= MaxQuestions || timeSinceStart >= MaxDuration`
- On limit reached: trigger roast flow, show pulsing `[FINAL QUESTION]` alert in status bar

**Status Bar:**

- Render: `Question X/10 | Time: MM:SS | [FINAL QUESTION]` (if approaching limit)
- Use `tea.Tick` for time updates (1-second interval)
- Pulsing effect via alternating border color (if color enabled)

**Metadata Tracking:**

- Track: `questionCount`, `surrenderCount`, `sessionStartTime`, `totalDuration`
- Store in model (not persisted to disk in v0.1.1, that's v0.1.2)

### 4. CLI Integration

**`internal/cli/mock.go`**:

- `prepf mock` command (optional `--resume PATH` flag)
- Load config from context
- Initialize AI client with config
- Launch TUI via `tea.NewProgram(mockModel)`
- Handle resume path: if not provided, check profile.CVPath

### 5. UI Components

**User Input:**

- Use `bubbles/textinput` (similar to SearchModel) for answer input
- Multi-line support (CharLimit: 2000)
- Enter submits, Esc cancels (but in interview context, maybe just clear?)

**AI Response Display:**

- Stream to viewport as chunks arrive
- Lock user input while streaming (`InterviewAIThinking` state)
- Unlock when stream completes (`InterviewUserInput` state)

**Key Bindings (`internal/mock/keymap.go`):**

- Extend `ui.KeyMap` with `Surrender` (Tab)
- Override `Tab` behavior in interview context (don't trigger base model search)
- Help text updates in `internal/ui/help.go`

## Implementation Order

1. **Foundation**: Create mock package structure, state types, constants
2. **Protocol Engine**: Implement `<NEXT>`/`<ROAST>` parser
3. **Context Loader**: Resume file loading with tea.Cmd wrapper
4. **Core Model**: Interview state machine, AI streaming integration
5. **Roast System**: Grade calculation, rendering, remediation buttons
6. **Session Limits**: Time tracking, question counting, expiry handling
7. **CLI Command**: Wire up Cobra command and TUI launch
8. **UI Polish**: Status bar, pulsing alerts, inline micro-roasts
9. **Testing**: Interactive mode, edge cases (empty resume, AI errors, timeouts)

## Constants & Configuration

**`internal/mock/constants.go`**:

```go
const (
    MaxQuestions = 10
    MaxDurationMinutes = 15
    ShadowPromptSurrender = "User surrenders. Give a snappy 1-2 sentence correction and move on."
    InitialPromptTemplate = "Here is the user's resume:\n\n%s\n\nConduct a technical interview..."
)
```

**Grade thresholds** (based on surrender count):

- A: 0 surrenders
- B: 1-2 surrenders
- C: 3-4 surrenders
- D: 5-6 surrenders
- F: 7+ surrenders

## Integration Points

- **AI Client**: Use existing `ai.Client.StreamStartCmd()` and `ai.WaitForStreamChunkCmd()`
- **Base Model**: Embed `*ui.BaseModel`, delegate window resize, help overlay
- **Config**: Read `api_key`, `timeout`, `token_limit` from context
- **Profile**: Read `CVPath` if `--resume` not provided

## Edge Cases

- Resume file not found: Show error, continue without context
- AI streaming errors: Display error, allow user to retry or quit
- Empty resume content: Proceed with generic interview
- Protocol signals in middle of text: Parse correctly, strip cleanly
- User quits mid-interview: Graceful exit (no roast, no persistence)